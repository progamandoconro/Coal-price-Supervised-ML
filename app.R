# Shiny App with Supervised ML for Coal Price Prediction:

library(shiny)
library(shinydashboard)
library(randomForest)
library(caret)
library(zoo)
library(dplyr)
library(groupdata2)
library(ggplot2)
library(DT)
library(e1071)

normalize <- function(x) { 
    return((x - min(x)) / (max(x) - min(x)))
}

df=read.csv('carbon_3.csv')

df$Toneladas_diarias<- df[,11]
df$Valor_diario_a_pagar<- df[,13]

df<-df[,c(-11,-13)]

df <- select (df,-starts_with("date"))%>%
    select(-starts_with("date."))%>%
    na.aggregate(by='Anio')%>%
    na.aggregate(by='Mes')%>%
    na.aggregate(by='Dia')%>%
    na.aggregate()

df$cat= paste(df[,1], df[,2])
df$cat=as.factor(df$cat)
levels(df$cat) <- 1:118
df$cat <- as.numeric(df$cat)

df <- balance(df,size='max', cat_col='cat')%>%
    lapply(normalize)%>%
    as.data.frame()

predicciones <- read.csv ('predicciones.csv')

ui <- dashboardPage(
    dashboardHeader(title="Predicción Carbón"),
    dashboardSidebar(
        selectInput("target","Variable a predecir",c("Toneladas_diarias","Valor_diario_a_pagar")),
        h5("Parámetros de afinación del Algoritmo"),
        h5("Random Forest:"),
        numericInput("p1","ntree",534),
        numericInput("p2","mtry",sqrt(200)),
        h5("*El valor de mtry es llevado a su raíz cuadrada"),
        numericInput("p3","seed",777),
        h5("Predicciones"),
        sliderInput("p4","Ajuste de probabilidad de clases",min=0.1,max=0.9,value=0.499),
        sliderInput("p5","Número de meses a futuro",min=1,max=36,value=1)
        
    ),
    dashboardBody(tabItem('item',tabsetPanel(tabPanel('Validación',
                 h5('Predicciones para las subidas y bajadas en el peso del Carbón ingresado y del valor facturado'),
                 h5("Matríz de Validación (Verde = éxito en la predicción, rojo = falla en la predicción)"),
                 plotOutput('plot'),
                 h5('VN = Verdaderos Negativos, FN = Falsos Negativos, FP = Falsos Positivos, VP = Verdaderos Positivos')
    ),
    tabPanel('Evaluación',
             h5('Resultados de las predicciones en 10 meses totalmente desconocidos para el algoritmo RF. '),
             h5('Esta sección de la data no se utilizó para el entrenamiento del algoritmo, sino que fue exclusiva para la evaluación y registro del error.'),
             DT::dataTableOutput("table")  
    ),
    
    tabPanel('Predicciones',
             h3("El algoritmo Random Forest, con los parámeros afinados, arroja que: "),
             textOutput("results"),
             h3("Probabilidad de cambio en el precio y peso futuros del carbón:"),
             dataTableOutput("table2")
             )
    
    ))))

server <- function(input, output) {
    output$plot <- renderPlot({
        
        m=input$p5
        n=28*m
        var_expl<- df
        target<-df[,input$target]
        df_cruz <- data.frame(target,var_expl)
        target<- vector()
        
        for (i in 1:NROW(df_cruz[,1])) {       
            target[i]<-ifelse( df_cruz[i,1]<df_cruz[i+n,1],1,0 )       
        }
        
        df_cruz$target<- target
        df_cruz<-df_cruz[1:(nrow(df_cruz)-n),]
        df_cruz <- df_cruz[1:(nrow(df_cruz)-220),]
        
        set.seed(input$p3)
        index <- sample(1:nrow(df_cruz),nrow(df_cruz))
        train <- df_cruz[1:floor(nrow(df_cruz)*0.7),]
        val <- df_cruz[(floor(nrow(df_cruz)*0.7)+1):nrow(df_cruz),]
       
        set.seed(input$p3)
        rF <- randomForest (train$target~.,ntree=input$p1, 
                            mtry=sqrt(input$p2) ,data=train[,-1], 
                            scale=T, importance=T,replace=T)
        
        p2 <- predict(rF, val[,-1])
        p2<- ifelse(p2<input$p4,0,1)
        cM <- confusionMatrix(as.factor(p2),as.factor(val[,1]))
        
        l<- as.data.frame(cM[2])
        
        l<-l[3]
        l<-as.vector(l)
        l<-c(l)
        
        ctable <- as.table(matrix(as.vector(unlist(l)), nrow = 2, byrow = TRUE))
        fourfoldplot(ctable, color = c( "#CC6666","#99CC99"),
                     conf.level = 0, margin = 2,main="") + 
            text(-0.4,0.4, "VN", cex=1) + 
            text(0.4, -0.4, "VP", cex=1) + 
            text(0.4,0.4, "FN", cex=1) + 
            text(-0.4, -0.4, "FP", cex=1)
        
    })
    
    output$table = DT::renderDataTable({
        
        m=input$p5
        n=28*m
        var_expl<- df
        target<-df[,input$target]
        df_cruz <- data.frame(target,var_expl)
        
        target<- vector()
        
        for (i in 1:NROW(df_cruz[,1])) {
            
            target[i]<-ifelse( df_cruz[i,1]<df_cruz[i+n,1],1,0 )
            
        }
        
        df_fut <-df_cruz[(nrow(df_cruz)-(n-1)):nrow(df_cruz),]
        df_cruz$target<- target
        df_cruz<-df_cruz[1:(nrow(df_cruz)-n),]
        
        test= df_cruz[(nrow(df_cruz)-220):(nrow(df_cruz)),]
        
        df_cruz <- df_cruz[1:(nrow(df_cruz)-220),]
        set.seed(input$p3)
        
        index <- sample(1:nrow(df_cruz),nrow(df_cruz))
        
        train <- df_cruz[1:floor(nrow(df_cruz)*0.7),]
        
        set.seed(input$p3)
        rF <- randomForest (train$target~.,ntree=input$p1, 
                            mtry=sqrt(input$p2) ,data=train[,-1],
                            scale=T, importance=T,replace=T)
        
        p2 <- predict(rF, test[,-1])
        p2<- ifelse(p2<input$p4,0,1)
        
        cM=confusionMatrix(as.factor(p2),as.factor(test[,1]))
        as.data.frame(unlist(cM))
        
    })
    
    output$results = renderText({
        
        m=input$p5
        n=28*m
        var_expl<- df
        target<-df[,input$target]
        df_cruz <- data.frame(target,var_expl)
        
        target<- vector()
        for (i in 1:NROW(df_cruz[,1])) {
            
            target[i]<-ifelse( df_cruz[i,1]<df_cruz[i+n,1],1,0 )
            
        }
        
        df_fut <-df_cruz[(nrow(df_cruz)-n):nrow(df_cruz),]
        df_cruz$target<- target
        df_cruz<-df_cruz[1:(nrow(df_cruz)-n),]
        df_cruz <- df_cruz[1:(nrow(df_cruz)-220),]
        
        set.seed(input$p3)
        index <- sample(1:nrow(df_cruz),nrow(df_cruz))
        train <- df_cruz[1:floor(nrow(df_cruz)*0.7),]
        
        set.seed(input$p3)
        rF <- randomForest (train$target~.,ntree=input$p1, 
                            mtry=sqrt(input$p2) ,data=train[,-1], 
                            scale=T, importance=T,replace=T)
        
        p2 <- predict(rF, df_fut[,-1])
        p2<- ifelse(p2<input$p4,0,1)
        
        paste("La probabilidad de cambio de", input$target,"dentro de", 
              input$p5, "mes es de:",   ( sum( as.numeric(as.vector(p2))) / nrow(df_fut) ),
              " +- ",( sd( as.numeric(as.vector(p2))) / nrow(df_fut) )) 
        
    })

    output$table2 = DT:: renderDataTable({
        predicciones
    })  
}

shinyApp(ui, server)
